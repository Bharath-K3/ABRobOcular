# ABRobOcular: Adversarial Benchmarking and Robustness for Ocular Biometrics

[![Paper](https://img.shields.io/badge/Paper-ðŸ“„Neurocomputing-red)](https://www.sciencedirect.com/science/article/pii/S0925231225010240)
[![Dataset](https://img.shields.io/badge/Dataset-ðŸ¤—%20Hugging%20Face-yellow)](https://huggingface.co/datasets/BharathK333/ABRobOcular_Attacks)
[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

A comprehensive library for evaluating and defending against adversarial attacks in ocular biometric systems.

## Abstract
Ocular biometrics, leveraging the unique traits of the eye region, stands as the pinnacle of cutting-edge technology. They have been widely adopted for identity verification and healthcare applications, and seamlessly integrated into products by tech giants like Meta and Apple. However, despite their rapid adoption and transformative potential, the vulnerability of ocular biometrics to sophisticated adversarial attacks remains alarmingly unaddressed. 

Adversarial attacks involve using digitally altered data to deceive deep learning models into producing incorrect outputs. Understanding the vulnerability of ocular biometrics against adversarial attacks and the potential of proposed defenses is vital to the robust deployment of secure and reliable technology on a global scale.

The aim of this paper is to investigate black-box and white-box-based adversarial attacks against ocular-based user recognition algorithms.
To this end, we benchmark the impact of $2$ ocular-specific, black-box adversarial attacks, and $5$ popular white-box adversarial attacks alongside their counterpart $9$ defenses across multiple datasets. In addition, we propose $3$ unified defenses against joint black-box and white-box attacks.
To the best of our knowledge, this is the first comprehensive study of its kind. To facilitate further research, we are releasing the ocular image datasets with adversarial attacks, as well as the evaluation code, under the ABRobOcular library, providing a valuable resource for future work in the field.

![alt text](assets/taxonomy.jpg)

## Directory Structure
```plaintext
ABRobOcular/
â”œâ”€â”€ AB_Rob_Ocular/
â”‚   â”œâ”€â”€ AB_Rob_Ocular_Tensor.py
â”‚   â”œâ”€â”€ AB_Rob_Ocular_Torch.py
â”‚   â”œâ”€â”€ extras.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ Adversarial_Images/
â”œâ”€â”€ Black-Box Defense/
â”‚   â”œâ”€â”€ Augmentation_Strip_ArcFace.ipynb
â”‚   â”œâ”€â”€ Patch_Visualization.ipynb
â”‚   â”œâ”€â”€ Strip_Visualization.ipynb
â”œâ”€â”€ Detection_and_Attribution/
â”‚   â”œâ”€â”€ Complete_DA_Network.ipynb
â”‚   â”œâ”€â”€ dataset_loader.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ eval.py
â”‚   â””â”€â”€ predict.py
â”œâ”€â”€ ocular_recognition/
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ test/
â”‚   â””â”€â”€ validation/
â”œâ”€â”€ trained_models/
â”œâ”€â”€ Base_Model.ipynb
â”œâ”€â”€ config.yml
â”œâ”€â”€ dataset_loader.py
â”œâ”€â”€ eval.py
â”œâ”€â”€ fgsm_sample_run.py
â”œâ”€â”€ predict.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ train.py
```

## Installation
To install ABRobOcular, follow these steps:
```bash
git clone https://github.com/yourusername/ABRobOcular.git
cd ABRobOcular
pip install -r requirements.txt
```

## Citation
Please cite us if you find our work useful
```bibtex
@article{krishnamurthy2025abrobocular,
  title={ABRobOcular: Adversarial benchmarking and robustness analysis of datasets and tools for ocular-based user recognition},
  author={Krishnamurthy, Bharath and Rattani, Ajita},
  journal={Neurocomputing},
  pages={130352},
  year={2025},
  publisher={Elsevier}
}
```

## Acknowledgements
This work is supported in part by the National Science Foundation (NSF) , United States award no. 2345561.
![alt text](assets/NSF_Logo.png)