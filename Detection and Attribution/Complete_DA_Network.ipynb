{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Detection and Attribution Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), name='arc_face/Softmax:0', description=\"created by layer 'arc_face'\")\n",
      "Found 65988 images belonging to 5 classes.\n",
      "Found 21073 images belonging to 5 classes.\n",
      "Found 21073 images belonging to 5 classes.\n",
      "Epoch 1/100\n",
      "4125/4125 [==============================] - 1127s 272ms/step - loss: 18.8503 - accuracy: 0.2754 - val_loss: 15.0717 - val_accuracy: 0.6642 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "4125/4125 [==============================] - 319s 77ms/step - loss: 13.7258 - accuracy: 0.5192 - val_loss: 10.9662 - val_accuracy: 0.7195 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "4125/4125 [==============================] - 307s 74ms/step - loss: 11.1549 - accuracy: 0.5861 - val_loss: 8.1308 - val_accuracy: 0.7806 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "4125/4125 [==============================] - 304s 74ms/step - loss: 8.3172 - accuracy: 0.6548 - val_loss: 4.8717 - val_accuracy: 0.8681 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "4125/4125 [==============================] - 306s 74ms/step - loss: 5.7525 - accuracy: 0.7419 - val_loss: 3.0783 - val_accuracy: 0.9171 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "4125/4125 [==============================] - 306s 74ms/step - loss: 4.1915 - accuracy: 0.8126 - val_loss: 2.3707 - val_accuracy: 0.9354 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "4125/4125 [==============================] - 305s 74ms/step - loss: 3.2443 - accuracy: 0.8553 - val_loss: 1.7857 - val_accuracy: 0.9528 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "4125/4125 [==============================] - 306s 74ms/step - loss: 2.5481 - accuracy: 0.8836 - val_loss: 1.4838 - val_accuracy: 0.9621 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "4125/4125 [==============================] - 307s 74ms/step - loss: 2.0724 - accuracy: 0.9036 - val_loss: 1.2873 - val_accuracy: 0.9687 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "4125/4125 [==============================] - 308s 75ms/step - loss: 1.7243 - accuracy: 0.9202 - val_loss: 1.0230 - val_accuracy: 0.9743 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "4125/4125 [==============================] - 308s 75ms/step - loss: 1.4822 - accuracy: 0.9308 - val_loss: 0.9601 - val_accuracy: 0.9766 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "4125/4125 [==============================] - 309s 75ms/step - loss: 1.2862 - accuracy: 0.9395 - val_loss: 0.8268 - val_accuracy: 0.9795 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "4125/4125 [==============================] - 311s 75ms/step - loss: 1.1303 - accuracy: 0.9471 - val_loss: 0.7343 - val_accuracy: 0.9824 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "4125/4125 [==============================] - 306s 74ms/step - loss: 1.0407 - accuracy: 0.9519 - val_loss: 0.6929 - val_accuracy: 0.9848 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "4125/4125 [==============================] - 308s 75ms/step - loss: 0.9267 - accuracy: 0.9572 - val_loss: 0.6692 - val_accuracy: 0.9837 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "4125/4125 [==============================] - 308s 75ms/step - loss: 0.8505 - accuracy: 0.9604 - val_loss: 0.5729 - val_accuracy: 0.9871 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "4125/4125 [==============================] - 300s 73ms/step - loss: 0.8079 - accuracy: 0.9636 - val_loss: 0.5816 - val_accuracy: 0.9866 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "4125/4125 [==============================] - 307s 75ms/step - loss: 0.7454 - accuracy: 0.9662 - val_loss: 0.5145 - val_accuracy: 0.9880 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "4125/4125 [==============================] - 308s 75ms/step - loss: 0.7203 - accuracy: 0.9672 - val_loss: 0.4930 - val_accuracy: 0.9880 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "4125/4125 [==============================] - 308s 75ms/step - loss: 0.6716 - accuracy: 0.9703 - val_loss: 0.4876 - val_accuracy: 0.9890 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "4125/4125 [==============================] - 307s 74ms/step - loss: 0.6500 - accuracy: 0.9709 - val_loss: 0.4736 - val_accuracy: 0.9896 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "4125/4125 [==============================] - 309s 75ms/step - loss: 0.6234 - accuracy: 0.9727 - val_loss: 0.4368 - val_accuracy: 0.9905 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "4125/4125 [==============================] - 308s 75ms/step - loss: 0.5774 - accuracy: 0.9755 - val_loss: 0.4190 - val_accuracy: 0.9905 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "4125/4125 [==============================] - 310s 75ms/step - loss: 0.5581 - accuracy: 0.9757 - val_loss: 0.4013 - val_accuracy: 0.9915 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "4125/4125 [==============================] - 312s 76ms/step - loss: 0.5562 - accuracy: 0.9761 - val_loss: 0.3774 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "4125/4125 [==============================] - 301s 73ms/step - loss: 0.5295 - accuracy: 0.9770 - val_loss: 0.4445 - val_accuracy: 0.9898 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "4125/4125 [==============================] - 299s 73ms/step - loss: 0.5308 - accuracy: 0.9774 - val_loss: 0.4356 - val_accuracy: 0.9897 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "4125/4125 [==============================] - 308s 75ms/step - loss: 0.5050 - accuracy: 0.9790 - val_loss: 0.3745 - val_accuracy: 0.9917 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "4125/4125 [==============================] - 310s 75ms/step - loss: 0.4942 - accuracy: 0.9795 - val_loss: 0.3465 - val_accuracy: 0.9920 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "4125/4125 [==============================] - 306s 74ms/step - loss: 0.4861 - accuracy: 0.9794 - val_loss: 0.3796 - val_accuracy: 0.9923 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "4125/4125 [==============================] - 305s 74ms/step - loss: 0.4611 - accuracy: 0.9808 - val_loss: 0.3550 - val_accuracy: 0.9922 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "4125/4125 [==============================] - 306s 74ms/step - loss: 0.4454 - accuracy: 0.9815 - val_loss: 0.3780 - val_accuracy: 0.9914 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "4125/4125 [==============================] - 306s 74ms/step - loss: 0.4468 - accuracy: 0.9814 - val_loss: 0.3712 - val_accuracy: 0.9918 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "4125/4125 [==============================] - 315s 76ms/step - loss: 0.4621 - accuracy: 0.9812 - val_loss: 0.3237 - val_accuracy: 0.9929 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "4125/4125 [==============================] - 307s 74ms/step - loss: 0.4334 - accuracy: 0.9818 - val_loss: 0.3242 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "4125/4125 [==============================] - 313s 76ms/step - loss: 0.4197 - accuracy: 0.9832 - val_loss: 0.3389 - val_accuracy: 0.9921 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "4125/4125 [==============================] - 322s 78ms/step - loss: 0.4130 - accuracy: 0.9831 - val_loss: 0.3547 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "4125/4125 [==============================] - 320s 78ms/step - loss: 0.4200 - accuracy: 0.9828 - val_loss: 0.3385 - val_accuracy: 0.9934 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "4125/4125 [==============================] - 325s 79ms/step - loss: 0.4133 - accuracy: 0.9838 - val_loss: 0.3208 - val_accuracy: 0.9927 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "4125/4125 [==============================] - 318s 77ms/step - loss: 0.4003 - accuracy: 0.9838 - val_loss: 0.3353 - val_accuracy: 0.9926 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "4125/4125 [==============================] - 327s 79ms/step - loss: 0.3926 - accuracy: 0.9846 - val_loss: 0.3100 - val_accuracy: 0.9930 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "4125/4125 [==============================] - 318s 77ms/step - loss: 0.3932 - accuracy: 0.9847 - val_loss: 0.3104 - val_accuracy: 0.9940 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "4125/4125 [==============================] - 319s 77ms/step - loss: 0.3992 - accuracy: 0.9842 - val_loss: 0.3594 - val_accuracy: 0.9923 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "4125/4125 [==============================] - 320s 78ms/step - loss: 0.3889 - accuracy: 0.9842 - val_loss: 0.3102 - val_accuracy: 0.9935 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "4125/4125 [==============================] - 319s 77ms/step - loss: 0.3828 - accuracy: 0.9852 - val_loss: 0.3490 - val_accuracy: 0.9929 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "4125/4125 [==============================] - 322s 78ms/step - loss: 0.3636 - accuracy: 0.9853 - val_loss: 0.3703 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "4125/4125 [==============================] - 321s 78ms/step - loss: 0.3733 - accuracy: 0.9858 - val_loss: 0.3174 - val_accuracy: 0.9936 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "4125/4125 [==============================] - 321s 78ms/step - loss: 0.3710 - accuracy: 0.9856 - val_loss: 0.3834 - val_accuracy: 0.9916 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "4125/4125 [==============================] - 323s 78ms/step - loss: 0.3710 - accuracy: 0.9859 - val_loss: 0.3458 - val_accuracy: 0.9928 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "4125/4125 [==============================] - 329s 80ms/step - loss: 0.3608 - accuracy: 0.9859 - val_loss: 0.2982 - val_accuracy: 0.9942 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "4125/4125 [==============================] - 319s 77ms/step - loss: 0.3491 - accuracy: 0.9863 - val_loss: 0.3046 - val_accuracy: 0.9939 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "4125/4125 [==============================] - 329s 80ms/step - loss: 0.3577 - accuracy: 0.9862 - val_loss: 0.2926 - val_accuracy: 0.9937 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "4125/4125 [==============================] - 327s 79ms/step - loss: 0.3536 - accuracy: 0.9865 - val_loss: 0.2829 - val_accuracy: 0.9940 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "4125/4125 [==============================] - 318s 77ms/step - loss: 0.3624 - accuracy: 0.9861 - val_loss: 0.3103 - val_accuracy: 0.9937 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "4125/4125 [==============================] - 316s 77ms/step - loss: 0.3553 - accuracy: 0.9865 - val_loss: 0.2884 - val_accuracy: 0.9940 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "4125/4125 [==============================] - 316s 77ms/step - loss: 0.3335 - accuracy: 0.9873 - val_loss: 0.3053 - val_accuracy: 0.9941 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "4125/4125 [==============================] - 316s 77ms/step - loss: 0.3350 - accuracy: 0.9871 - val_loss: 0.3163 - val_accuracy: 0.9935 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "4125/4125 [==============================] - 317s 77ms/step - loss: 0.3405 - accuracy: 0.9872 - val_loss: 0.3345 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "4125/4125 [==============================] - 319s 77ms/step - loss: 0.3510 - accuracy: 0.9871 - val_loss: 0.2887 - val_accuracy: 0.9933 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "4125/4125 [==============================] - 330s 80ms/step - loss: 0.3431 - accuracy: 0.9871 - val_loss: 0.2796 - val_accuracy: 0.9942 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "4125/4125 [==============================] - 322s 78ms/step - loss: 0.3286 - accuracy: 0.9871 - val_loss: 0.2984 - val_accuracy: 0.9938 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "4125/4125 [==============================] - 321s 78ms/step - loss: 0.3298 - accuracy: 0.9874 - val_loss: 0.3684 - val_accuracy: 0.9927 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "4125/4125 [==============================] - 319s 77ms/step - loss: 0.3320 - accuracy: 0.9878 - val_loss: 0.3316 - val_accuracy: 0.9936 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "4125/4125 [==============================] - 320s 78ms/step - loss: 0.3225 - accuracy: 0.9879 - val_loss: 0.2950 - val_accuracy: 0.9940 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "4125/4125 [==============================] - 319s 77ms/step - loss: 0.3225 - accuracy: 0.9878 - val_loss: 0.3128 - val_accuracy: 0.9937 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "4125/4125 [==============================] - 320s 78ms/step - loss: 0.3080 - accuracy: 0.9885 - val_loss: 0.3777 - val_accuracy: 0.9927 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "4125/4125 [==============================] - 320s 78ms/step - loss: 0.3097 - accuracy: 0.9884 - val_loss: 0.2856 - val_accuracy: 0.9944 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "4125/4125 [==============================] - 320s 78ms/step - loss: 0.3134 - accuracy: 0.9880 - val_loss: 0.3071 - val_accuracy: 0.9939 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "4125/4125 [==============================] - 320s 77ms/step - loss: 0.3058 - accuracy: 0.9887 - val_loss: 0.3166 - val_accuracy: 0.9939 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "4125/4125 [==============================] - 320s 78ms/step - loss: 0.3194 - accuracy: 0.9883 - val_loss: 0.3230 - val_accuracy: 0.9937 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "4125/4125 [==============================] - 320s 78ms/step - loss: 0.3114 - accuracy: 0.9884 - val_loss: 0.3058 - val_accuracy: 0.9937 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "4125/4125 [==============================] - 321s 78ms/step - loss: 0.3028 - accuracy: 0.9886 - val_loss: 0.2958 - val_accuracy: 0.9938 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "4125/4125 [==============================] - 323s 78ms/step - loss: 0.2989 - accuracy: 0.9886 - val_loss: 0.2798 - val_accuracy: 0.9944 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "4125/4125 [==============================] - 321s 78ms/step - loss: 0.3049 - accuracy: 0.9887 - val_loss: 0.2923 - val_accuracy: 0.9933 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "4125/4125 [==============================] - 317s 77ms/step - loss: 0.3005 - accuracy: 0.9893 - val_loss: 0.3151 - val_accuracy: 0.9932 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "4125/4125 [==============================] - 328s 79ms/step - loss: 0.3023 - accuracy: 0.9891 - val_loss: 0.2773 - val_accuracy: 0.9944 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "4125/4125 [==============================] - 326s 79ms/step - loss: 0.3101 - accuracy: 0.9886 - val_loss: 0.2633 - val_accuracy: 0.9943 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "4125/4125 [==============================] - 318s 77ms/step - loss: 0.2905 - accuracy: 0.9895 - val_loss: 0.3127 - val_accuracy: 0.9941 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "4125/4125 [==============================] - 318s 77ms/step - loss: 0.2996 - accuracy: 0.9891 - val_loss: 0.2672 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "4125/4125 [==============================] - 319s 77ms/step - loss: 0.2928 - accuracy: 0.9893 - val_loss: 0.2987 - val_accuracy: 0.9938 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "4125/4125 [==============================] - 319s 77ms/step - loss: 0.2882 - accuracy: 0.9894 - val_loss: 0.3052 - val_accuracy: 0.9940 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "4125/4125 [==============================] - 320s 77ms/step - loss: 0.2938 - accuracy: 0.9897 - val_loss: 0.2902 - val_accuracy: 0.9944 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "4125/4125 [==============================] - 320s 78ms/step - loss: 0.2956 - accuracy: 0.9893 - val_loss: 0.3168 - val_accuracy: 0.9940 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "4125/4125 [==============================] - 320s 78ms/step - loss: 0.2949 - accuracy: 0.9893 - val_loss: 0.2892 - val_accuracy: 0.9946 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "4125/4125 [==============================] - 323s 78ms/step - loss: 0.2916 - accuracy: 0.9894 - val_loss: 0.2889 - val_accuracy: 0.9941 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "4125/4125 [==============================] - 322s 78ms/step - loss: 0.2763 - accuracy: 0.9900 - val_loss: 0.3143 - val_accuracy: 0.9920 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "4125/4125 [==============================] - 319s 77ms/step - loss: 0.2873 - accuracy: 0.9893 - val_loss: 0.2738 - val_accuracy: 0.9947 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "4125/4125 [==============================] - 320s 78ms/step - loss: 0.2792 - accuracy: 0.9900 - val_loss: 0.2848 - val_accuracy: 0.9944 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "4125/4125 [==============================] - 320s 78ms/step - loss: 0.2853 - accuracy: 0.9893 - val_loss: 0.2653 - val_accuracy: 0.9950 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "4125/4125 [==============================] - 320s 78ms/step - loss: 0.2739 - accuracy: 0.9898 - val_loss: 0.2912 - val_accuracy: 0.9944 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "4125/4125 [==============================] - 316s 77ms/step - loss: 0.2892 - accuracy: 0.9900 - val_loss: 0.2801 - val_accuracy: 0.9945 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "4125/4125 [==============================] - 314s 76ms/step - loss: 0.2894 - accuracy: 0.9898 - val_loss: 0.3347 - val_accuracy: 0.9935 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "4125/4125 [==============================] - 314s 76ms/step - loss: 0.2888 - accuracy: 0.9899 - val_loss: 0.2975 - val_accuracy: 0.9941 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "4125/4125 [==============================] - 315s 76ms/step - loss: 0.2873 - accuracy: 0.9896 - val_loss: 0.2679 - val_accuracy: 0.9949 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "4125/4125 [==============================] - 316s 77ms/step - loss: 0.2687 - accuracy: 0.9901 - val_loss: 0.2765 - val_accuracy: 0.9942 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "4125/4125 [==============================] - 315s 76ms/step - loss: 0.2695 - accuracy: 0.9901 - val_loss: 0.2675 - val_accuracy: 0.9950 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "4125/4125 [==============================] - 316s 77ms/step - loss: 0.2761 - accuracy: 0.9900 - val_loss: 0.2832 - val_accuracy: 0.9945 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eeb200cfa0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained Xception model\n",
    "base_model = tf.keras.applications.Xception(input_shape=(256, 256, 3),\n",
    "                                            include_top=False,\n",
    "                                            weights='imagenet')\n",
    "\n",
    "# Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False\n",
    "\n",
    "# Defining my ArcFace Function\n",
    "class ArcFace(layers.Layer):\n",
    "    def __init__(self, n_classes=5, s=64.0, m=0.50, regularizer=None, **kwargs):\n",
    "        super(ArcFace, self).__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.regularizer = regularizer\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcFace, self).build(input_shape[0])\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                 shape=(input_shape[0][-1], self.n_classes),\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True,\n",
    "                                 regularizer=self.regularizer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, y = inputs\n",
    "        c = tf.shape(x)[-1]\n",
    "        # normalize feature\n",
    "        x = tf.nn.l2_normalize(x, axis=1)\n",
    "        # normalize weights\n",
    "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
    "        # dot product\n",
    "        logits = x @ W\n",
    "        # add margin\n",
    "        theta = tf.acos(tf.clip_by_value(logits, -1.0 + tf.keras.backend.epsilon(), 1.0 - tf.keras.backend.epsilon()))\n",
    "        target_logits = tf.cos(theta + self.m)\n",
    "        logits = logits * (1 - y) + target_logits * y\n",
    "        # feature re-scale\n",
    "        logits *= self.s\n",
    "        out = tf.nn.softmax(logits)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'regularizer': self.regularizer,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# Add new layers\n",
    "x = base_model.output\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Placeholder for label input\n",
    "y = tf.keras.Input(shape=(5,))  # We have 5 classes currerntly\n",
    "output = ArcFace(n_classes=5)([x, y])\n",
    "print(output)\n",
    "\n",
    "# Define the new model\n",
    "model = Model(inputs=[base_model.input, y], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define the parameters for the ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load the training data\n",
    "train_data = datagen.flow_from_directory(\n",
    "    'multi-detector/train',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse')\n",
    "\n",
    "# Load the validation data\n",
    "validation_data = datagen.flow_from_directory(\n",
    "    'multi-detector/validation',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse')\n",
    "\n",
    "# Load the test data\n",
    "test_data = datagen.flow_from_directory(\n",
    "    'multi-detector/test',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse')\n",
    "\n",
    "def arcface_generator(generator):\n",
    "    while True:\n",
    "        data = next(generator)\n",
    "        yield [data[0], tf.one_hot(data[1], depth=5)], tf.one_hot(data[1], depth=5)\n",
    "\n",
    "# Create the new generators\n",
    "train_generator = arcface_generator(train_data)\n",
    "validation_generator = arcface_generator(validation_data)\n",
    "test_generator = arcface_generator(test_data)\n",
    "\n",
    "# Set up callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "os.makedirs('trained_models', exist_ok=True)\n",
    "model_checkpoint = ModelCheckpoint('trained_models/Xception_Multi_Detector.h5', save_best_only=True)\n",
    "\n",
    "callbacks = [early_stop, reduce_lr, model_checkpoint]\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow()\n",
    "model.fit(train_generator,\n",
    "          validation_data=validation_generator,\n",
    "          steps_per_epoch=len(train_data), \n",
    "          validation_steps=len(validation_data),\n",
    "          epochs=100,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 65988 images belonging to 5 classes.\n",
      "Found 21073 images belonging to 5 classes.\n",
      "Found 21073 images belonging to 5 classes.\n",
      "10000/10000 [==============================] - 718s 72ms/step - loss: 0.2807 - accuracy: 0.9946\n",
      "Test accuracy: 0.9946339726448059\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Defining my ArcFace Function\n",
    "class ArcFace(layers.Layer):\n",
    "    def __init__(self, n_classes=5, s=64.0, m=0.50, regularizer=None, **kwargs):\n",
    "        super(ArcFace, self).__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.regularizer = regularizer\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcFace, self).build(input_shape[0])\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                 shape=(input_shape[0][-1], self.n_classes),\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True,\n",
    "                                 regularizer=self.regularizer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, y = inputs\n",
    "        c = tf.shape(x)[-1]\n",
    "        # normalize feature\n",
    "        x = tf.nn.l2_normalize(x, axis=1)\n",
    "        # normalize weights\n",
    "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
    "        # dot product\n",
    "        logits = x @ W\n",
    "        # add margin\n",
    "        theta = tf.acos(tf.clip_by_value(logits, -1.0 + tf.keras.backend.epsilon(), 1.0 - tf.keras.backend.epsilon()))\n",
    "        target_logits = tf.cos(theta + self.m)\n",
    "        logits = logits * (1 - y) + target_logits * y\n",
    "        # feature re-scale\n",
    "        logits *= self.s\n",
    "        out = tf.nn.softmax(logits)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'regularizer': self.regularizer,\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "# Load the saved model\n",
    "# model = load_model('trained_models/Xception_Multi_Detector.h5', custom_objects={'ArcFace': ArcFace})\n",
    "\n",
    "# Define the parameters for the ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load the training data\n",
    "train_data = datagen.flow_from_directory(\n",
    "    'multi-detector/train',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse')\n",
    "\n",
    "# Load the validation data\n",
    "validation_data = datagen.flow_from_directory(\n",
    "    'multi-detector/validation',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse')\n",
    "\n",
    "# Load the test data\n",
    "test_data = datagen.flow_from_directory(\n",
    "    'multi-detector/test',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse')\n",
    "\n",
    "def arcface_generator(generator):\n",
    "    while True:\n",
    "        data = next(generator)\n",
    "        yield [data[0], tf.one_hot(data[1], depth=5)], tf.one_hot(data[1], depth=5)\n",
    "\n",
    "# Create the new generators\n",
    "train_generator = arcface_generator(train_data)\n",
    "validation_generator = arcface_generator(validation_data)\n",
    "test_generator = arcface_generator(test_data)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=10000)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute individual Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "The predicted class is: 3\n",
      "The predicted class is: No Attack\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the image\n",
    "img_path = 'multi-detector/test/No Attack/1141/1141_l_1.png'\n",
    "img = image.load_img(img_path, target_size=(256, 256))\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "# Scale the image\n",
    "x = x / 255.0\n",
    "\n",
    "# Expand the dimensions to match the shape that the model expects\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# Prepare the dummy label input for the ArcFace layer\n",
    "dummy_label_input = np.zeros((1, 5))\n",
    "\n",
    "# Make the prediction\n",
    "predictions = model.predict([x, dummy_label_input])\n",
    "\n",
    "# The predictions are probabilities for each class. You can get the class with the highest probability like this:\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "print(f\"The predicted class is: {predicted_class}\")\n",
    "\n",
    "# Get the class indices\n",
    "class_indices = train_data.class_indices\n",
    "\n",
    "# Get the class names\n",
    "class_names = list(class_indices.keys())\n",
    "\n",
    "# Print the predicted class name\n",
    "print(f\"The predicted class is: {class_names[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "The predicted class is: 4\n",
      "The predicted class is: PGD\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the image\n",
    "img_path = 'multi-detector/test/PGD/1141/1141_l_1_pgd_01.png'\n",
    "img = image.load_img(img_path, target_size=(256, 256))\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "# Scale the image\n",
    "x = x / 255.0\n",
    "\n",
    "# Expand the dimensions to match the shape that the model expects\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# Prepare the dummy label input for the ArcFace layer\n",
    "dummy_label_input = np.zeros((1, 5))\n",
    "\n",
    "# Make the prediction\n",
    "predictions = model.predict([x, dummy_label_input])\n",
    "\n",
    "# The predictions are probabilities for each class. You can get the class with the highest probability like this:\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "print(f\"The predicted class is: {predicted_class}\")\n",
    "\n",
    "# Get the class indices\n",
    "class_indices = train_data.class_indices\n",
    "\n",
    "# Get the class names\n",
    "class_names = list(class_indices.keys())\n",
    "\n",
    "# Print the predicted class name\n",
    "print(f\"The predicted class is: {class_names[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "The predicted class is: 2\n",
      "The predicted class is: MIM\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the image\n",
    "img_path = 'multi-detector/test/MIM/3265/3265_l_1_mim_001.png'\n",
    "img = image.load_img(img_path, target_size=(256, 256))\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "# Scale the image\n",
    "x = x / 255.0\n",
    "\n",
    "# Expand the dimensions to match the shape that the model expects\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# Prepare the dummy label input for the ArcFace layer\n",
    "dummy_label_input = np.zeros((1, 5))\n",
    "\n",
    "# Make the prediction\n",
    "predictions = model.predict([x, dummy_label_input])\n",
    "\n",
    "# The predictions are probabilities for each class. You can get the class with the highest probability like this:\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "print(f\"The predicted class is: {predicted_class}\")\n",
    "\n",
    "# Get the class indices\n",
    "class_indices = train_data.class_indices\n",
    "\n",
    "# Get the class names\n",
    "class_names = list(class_indices.keys())\n",
    "\n",
    "# Print the predicted class name\n",
    "print(f\"The predicted class is: {class_names[predicted_class]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
